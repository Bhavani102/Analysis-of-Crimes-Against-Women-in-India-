# -*- coding: utf-8 -*-
"""Assignment4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sYHuZD9jAojFYLkMW1eI6iZ_8ysduAFU
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Load dataset
df = pd.read_csv('CrimesOnWomenData.csv')
# Summary statistics for numerical columns
print(df.head())

# Get a concise summary of the DataFrame
df.info()

# Summary statistics for numerical columns
print(df.describe())
# Check for missing values
print(df.isnull().sum())
# Check for duplicate rows
df.duplicated().sum()

# Fill missing values with 0 or appropriate strategy
df.fillna(0, inplace=True)
# Remove duplicate rows
df.drop_duplicates(inplace=True)
# Check data types
df.dtypes

# Convert Year to integer if not already
df['Year'] = df['Year'].astype(int)

# Ensure all crime columns are numeric
crime_columns = ['Rape', 'K&A', 'DD', 'AoW', 'AoM', 'DV', 'WT']
for col in crime_columns:
    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

# Rename columns for better readability
df.rename(columns={
    'K&A': 'Kidnap_and_Assault',
    'DD': 'Dowry_Deaths',
    'AoW': 'Assault_on_Women',
    'AoM': 'Assault_on_Modesty',
    'DV': 'Domestic_Violence',
    'WT': 'Women_Trafficking'
}, inplace=True)

# Calculate total crimes per year
df['Total_Crimes'] = df[['Rape', 'Kidnap_and_Assault', 'Dowry_Deaths', 'Assault_on_Women',
                         'Assault_on_Modesty', 'Domestic_Violence', 'Women_Trafficking']].sum(axis=1)

yearly_crimes = df.groupby('Year')['Total_Crimes'].sum().reset_index()
print (yearly_crimes)

# Convert state names to lowercase
df['State'] = df['State'].str.lower()
# Calculate total crimes per state
state_crimes = df.groupby('State')['Total_Crimes'].sum().reset_index().sort_values(by='Total_Crimes', ascending=False)
# Print all states
pd.set_option('display.max_rows', None)  # Ensure all rows are displayed
print(state_crimes)

# Get unique states
print("Unique States:", df['State'].nunique())

# Get range of years
print("Year range:", df['Year'].min(), "-", df['Year'].max())

# Line plot for total crimes over years
plt.figure(figsize=(12, 6))
sns.lineplot(data=yearly_crimes, x='Year', y='Total_Crimes', marker='o')
plt.title('Total Crimes Against Women in India (2001-2021)')
plt.xlabel('Year')
plt.ylabel('Number of Cases')
plt.xticks(yearly_crimes['Year'], rotation=45)
plt.tight_layout()
plt.show()

# Bar plot for top 10 states with highest crimes
# Calculate total crimes per state
state_crimes = df.groupby('State')['Total_Crimes'].sum().reset_index().sort_values(by='Total_Crimes', ascending=False)
top_10_states = state_crimes.head(10)

plt.figure(figsize=(12, 8))
sns.barplot(data=top_10_states, x='Total_Crimes', y='State', palette='Reds_r')
plt.title('Top 10 States by Total Crimes Against Women (2001-2021)')
plt.xlabel('Total Number of Cases')
plt.ylabel('State')
plt.tight_layout()
plt.show()

# List of crime columns to analyze
crime_columns = ['Rape', 'Kidnap_and_Assault', 'Dowry_Deaths', 'Assault_on_Women',
                 'Assault_on_Modesty', 'Domestic_Violence', 'Women_Trafficking']
# Loop through each crime type
for column_name in crime_columns:
    print(f'--- Statistics for {column_name} ---')
    #calcualte min
    min_value= df[column_name].min()
    #calcualte max
    max_value= df[column_name].max()
    # Calculate mean
    mean_value = df[column_name].mean()

    # Calculate median
    median_value = df[column_name].median()

    # Calculate quartiles
    q1 = df[column_name].quantile(0.25)
    q2 = df[column_name].quantile(0.50)  # This is the median
    q3 = df[column_name].quantile(0.75)

    # Calculate standard deviation
    std_dev = df[column_name].std()

    # Calculate mode
    mode_value = df[column_name].mode()[0]

    # Calculate variance
    variance_value = df[column_name].var()

    # Calculate Interquartile Range (IQR)
    iqr_value = q3 - q1

    cv = (std_dev / mean_value) * 100
    # Calculate skewness
    skewness_value = df[column_name].skew()

    # Calculate kurtosis
    kurtosis_value = df[column_name].kurtosis()

    # Print the results
    print(f'Minimum: {min_value}')
    print(f'Maximum: {max_value}')
    print(f'Mean: {mean_value}')
    print(f'Median: {median_value}')
    print(f'1st Quartile (Q1): {q1}')
    print(f'2nd Quartile (Median, Q2): {q2}')
    print(f'3rd Quartile (Q3): {q3}')
    print(f'Standard Deviation: {std_dev}')
    print(f'Mode: {mode_value}')
    print(f'Variance: {variance_value}')
    print(f'Interquartile Range (IQR): {iqr_value}')
    print(f'Coefficient of variation: {cv}')
    print(f'Skewness: {skewness_value}')
    print(f'Kurtosis: {kurtosis_value}')
    print('\n')

# Year-wise trend for Rape cases
rape_trend = df.groupby('Year')['Rape'].sum().reset_index()
rape_trend.head()

# Calculate correlation matrix
crime_types = ['Rape', 'Kidnap_and_Assault', 'Dowry_Deaths', 'Assault_on_Women',
               'Assault_on_Modesty', 'Domestic_Violence', 'Women_Trafficking']

correlation_matrix = df[crime_types].corr()
correlation_matrix

# List of crime columns to plot
crime_columns = ['Rape', 'Kidnap_and_Assault', 'Dowry_Deaths',
                 'Assault_on_Women', 'Assault_on_Modesty',
                 'Domestic_Violence', 'Women_Trafficking']

# Plotting Q-Plots for each crime type
plt.figure(figsize=(15, 10))

for i, col in enumerate(crime_columns, 1):
    plt.subplot(3, 3, i)  # Adjust subplot grid size according to the number of plots
    sorted_data = np.sort(df[col])
    p = np.arange(1, len(sorted_data) + 1) / len(sorted_data)
    plt.plot(sorted_data, p, marker='o', linestyle='none')
    plt.xlabel('Crime Cases')
    plt.ylabel('Proportion')
    plt.title(f'Q-Plot for {col}')

plt.tight_layout()
plt.show()

import scipy.stats as stats
# List of crime columns to plot
crime_columns = ['Rape', 'Kidnap_and_Assault', 'Dowry_Deaths',
                 'Assault_on_Women', 'Assault_on_Modesty',
                 'Domestic_Violence', 'Women_Trafficking']

# Plotting Q-Q plots for each crime type
plt.figure(figsize=(15, 10))

for i, col in enumerate(crime_columns, 1):
    plt.subplot(3, 3, i)  # Adjust subplot grid size according to the number of plots
    stats.probplot(df[col], dist="norm", plot=plt)
    plt.title(f'Q-Q Plot for {col}')

plt.tight_layout()
plt.show()

# Plotting Enhanced Box Plots with annotations for each crime type
plt.figure(figsize=(16, 25))

for i, col in enumerate(crime_columns, 1):
    plt.subplot(3, 3, i)

    # Customizing the color palette
    box_color = '#87CEEB'  # Light Sky Blue
    min_color = '#00FF00'  # Green for Min
    q1_color = '#0000FF'   # Blue for Q1
    median_color = '#FFA500' # Orange for Median
    q3_color = '#800080'   # Purple for Q3
    max_color = '#FF0000'  # Red for Max
    text_color = '#000000' # Black for annotations

    # Creating box plot
    sns.boxplot(y=df[col], color=box_color, linewidth=2, fliersize=5)

    # Calculating statistics
    stats = df[col].describe()
    min_val = stats['min']
    q1 = stats['25%']
    median = stats['50%']
    q3 = stats['75%']
    max_val = stats['max']

    # Drawing horizontal lines for Min, Q1, Median, Q3, Max
    plt.axhline(min_val, color=min_color, linestyle='-', linewidth=2, label=f'Min: {min_val:.2f}')
    plt.axhline(q1, color=q1_color, linestyle='-', linewidth=2, label=f'Q1: {q1:.2f}')
    plt.axhline(median, color=median_color, linestyle='-', linewidth=2, label=f'Median: {median:.2f}')
    plt.axhline(q3, color=q3_color, linestyle='-', linewidth=2, label=f'Q3: {q3:.2f}')
    plt.axhline(max_val, color=max_color, linestyle='-', linewidth=2, label=f'Max: {max_val:.2f}')

    # Annotating each statistic on the boxplot
    plt.text(0.1, min_val, f'Min: {min_val:.2f}', ha='left', va='center', color=text_color, fontsize=10)
    plt.text(0.1, q1, f'Q1: {q1:.2f}', ha='left', va='center', color=text_color, fontsize=10)
    plt.text(0.1, median, f'Median: {median:.2f}', ha='left', va='center', color=text_color, fontsize=10)
    plt.text(0.1, q3, f'Q3: {q3:.2f}', ha='left', va='center', color=text_color, fontsize=10)
    plt.text(0.1, max_val, f'Max: {max_val:.2f}', ha='left', va='center', color=text_color, fontsize=10)

    plt.title(f'Box Plot for {col}', color=text_color, fontsize=12)
    plt.ylabel('Number of Cases', color=text_color, fontsize=10)

    plt.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.show()

# Line plots for different crime types over years
plt.figure(figsize=(14, 8))

for crime in crime_types:
    yearly_data = df.groupby('Year')[crime].sum().reset_index()
    sns.lineplot(data=yearly_data, x='Year', y=crime, label=crime)

plt.title('Trend of Different Crimes Against Women Over Years')
plt.xlabel('Year')
plt.ylabel('Number of Cases')
plt.legend(title='Crime Type')
plt.xticks(yearly_crimes['Year'], rotation=45)
plt.tight_layout()
plt.show()

# Pivot table for heatmap
heatmap_data = df.pivot_table(values='Total_Crimes', index='State', columns='Year', aggfunc='sum', fill_value=0)

plt.figure(figsize=(20, 15))
sns.heatmap(heatmap_data, cmap='YlOrRd')
plt.title('Heatmap of Total Crimes Against Women by State and Year')
plt.xlabel('Year')
plt.ylabel('State')
plt.tight_layout()
plt.show()

# Heatmap for correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='Blues')
plt.title('Correlation Between Different Crime Types')
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(18, 12))

# Pairing up the crime types for scatter plots
pairs = [('Rape', 'Kidnap_and_Assault'),
         ('Dowry_Deaths', 'Domestic_Violence'),
         ('Assault_on_Women', 'Assault_on_Modesty')]

for i, (x_col, y_col) in enumerate(pairs, 1):
    plt.subplot(2, 3, i)

    # Scatter plot with regression line
    sns.scatterplot(x=df[x_col], y=df[y_col], color='blue', alpha=0.6, s=60)

    # Optional: Adding a regression line
    sns.regplot(x=df[x_col], y=df[y_col], scatter=False, color='red', line_kws={"linewidth":2})

    plt.title(f'{x_col} vs {y_col}', fontsize=14)
    plt.xlabel(f'{x_col}', fontsize=12)
    plt.ylabel(f'{y_col}', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

# Box plot for all crimes combined
plt.figure(figsize=(12, 8))
sns.boxplot(data=df[crime_columns])
plt.title('Box Plots for Different Crime Types')
plt.xlabel('Crime Type')
plt.ylabel('Number of Cases')
plt.xticks(rotation=45)
plt.show()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Prepare data for clustering: Summing total crimes for each state across years
crime_data = df.groupby('State')[crime_columns].sum()

# Standardize the data
scaler = StandardScaler()
crime_data_scaled = scaler.fit_transform(crime_data)

# Find the optimal number of clusters using the Elbow Method
inertia = []
for k in range(1, 10):  # Testing 1 to 9 clusters
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(crime_data_scaled)
    inertia.append(kmeans.inertia_)

# Plot the Elbow graph
plt.figure(figsize=(8, 5))
plt.plot(range(1, 10), inertia, marker='o', color='blue')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Inertia')
plt.show()

# Perform K-Means clustering with the optimal number of clusters (e.g., 3)
optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
crime_data['Cluster'] = kmeans.fit_predict(crime_data_scaled)

# Add cluster labels back to the original data
df = df.merge(crime_data[['Cluster']], left_on='State', right_index=True)

# Visualize Clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(
    x=crime_data_scaled[:, 0],  # First feature (Rape after scaling)
    y=crime_data_scaled[:, 1],  # Second feature (Kidnap_and_Assault after scaling)
    hue=crime_data['Cluster'], palette='viridis', s=100
)
plt.title('State Clustering Based on Crime Patterns')
plt.xlabel('Scaled Feature 1 (e.g., Rape)')
plt.ylabel('Scaled Feature 2 (e.g., Kidnap_and_Assault)')
plt.legend(title='Cluster')
plt.show()

# Display cluster-wise statistics
cluster_summary = crime_data.groupby('Cluster').mean()
print(cluster_summary)

# Add cluster labels to the original dataset
crime_data['Cluster'] = kmeans.labels_

# List states for each cluster
for cluster_num in range(optimal_k):  # Replace `optimal_k` with the number of clusters
    states_in_cluster = crime_data[crime_data['Cluster'] == cluster_num].index.tolist()
    print(f"\nStates in Cluster {cluster_num}:")
    print(", ".join(states_in_cluster))

from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# Aggregate data by year
yearly_crimes = df.groupby('Year')['Total_Crimes'].sum()

# Fit ARIMA model
arima_order = (1, 1, 1)  # Based on ACF/PACF plots, adjust parameters as needed
model = ARIMA(yearly_crimes, order=arima_order)
model_fit = model.fit()

# Forecast for the next 5 years
forecast = model_fit.forecast(steps=5)
print("Forecast for next 5 years:")
print(forecast)

# Plot actual vs forecast
plt.figure(figsize=(10, 6))
plt.plot(yearly_crimes, label='Actual Data', marker='o')
plt.plot(range(2022, 2027), forecast, label='Forecast', marker='x')
plt.title('Predicted Total Crimes Against Women (2022â€“2026)')
plt.xlabel('Year')
plt.ylabel('Total Crimes')
plt.legend()
plt.grid()
plt.show()